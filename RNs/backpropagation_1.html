<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Backpropagation (DeepAI)</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --select-text-bg-color: #B5D6FC; --select-text-font-color: auto; --monospace: "Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.428571; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 40px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font-style: inherit; font-variant-caps: inherit; font-weight: inherit; font-stretch: inherit; font-size: inherit; line-height: inherit; font-family: inherit; font-size-adjust: inherit; font-kerning: inherit; font-variant-alternates: inherit; font-variant-ligatures: inherit; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-variant-position: inherit; font-variant-emoji: inherit; font-feature-settings: inherit; font-optical-sizing: inherit; font-variation-settings: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right-width: 0px; border-right-style: none; border-right-color: currentcolor; background-color: inherit; }
.CodeMirror-linenumber { }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: medium; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: medium !important; border-style: none !important; border-color: currentcolor !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; font-size-adjust: none; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom-width: 0px; border-bottom-style: none; border-bottom-color: currentcolor; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: medium; }
.highlight td, .highlight tr { border: 0px; }
svg[id^="mermaidChart"] { line-height: 1em; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
mark .md-meta { color: rgb(0, 0, 0); opacity: 0.3 !important; }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
  .typora-export h1::after, .typora-export h2::after, .typora-export h3::after, .typora-export h4::after, .typora-export h5::after, .typora-export h6::after { content: ""; display: block; height: 100px; margin-bottom: -100px; }
}


import url(https://fonts.googleapis.com/css?family=Open%20Sans);
:root {
    --code-block-bg-color: inherit;//#f8f8f8;

    --item-hover-bg-color: #0a0d16;
    --control-text-color: #b7b7b7;
    --control-text-hover-color: #eee;
    --window-border: 1px dashed #9b9b9b;

    --active-file-bg-color: #0070E0;
    --active-file-border-color: #8d8df0;

    --primary-color: #a3d5fe;

    --active-file-text-color: #0070e0;
    --item-hover-bg-color: #70717d;
    --item-hover-text-color: white;
    --primary-color: #6dc1e7;
}

html,
body,
#write{
	color: #5e676d;
	font-family: "Open Sans", "Clear Sans", sans-serif;
}
h1,
h2,
h3,
h4,
h5,
h6 {
	/*font-weight: lighter;*/
	font-weight: 100;
	color: #5e676d;
	font-family: "Open Sans", sans-serif;
	margin: 0.5rem 0;
}

html {
	font-size:16px;
}

#write {
	max-width: 914px;
	text-align: justify;
}

#write>h1:first-child {
	margin-top: 2.75rem;
}
#write>h2:first-child {
	margin-top: 1.75rem;
}
#write>h3:first-child {
	margin-top: 1rem;
}
#write>h4:first-child {
	margin-top: 0.5rem;
}
h1 {
	margin: 1rem 0;
	/*line-height: 4rem;
	padding: 5px 30px;
	text-align: center;
	margin-top: 4rem;*/
}
h2 {
	margin: 0.8rem 0;
	/*
	line-height: 3rem;
	padding: 0 30px;
	text-align: center;
	margin-top: 3rem
	*/
}
h3 {
}
h4 {
}
h5 {
	font-size: 1.125rem;
}
h6 {
	font-size: 1.1rem;
}
p {
	color: #5e676d;
	font-size: 1rem;
	line-height: 1.5rem;
	margin: 0 0 1.25rem;
}
#write>h3.md-focus:before {
	left: -1.875rem;
	top: 0.5rem;
	padding: 2px;
}
#write>h4.md-focus:before {
	left: -1.875rem;
	top: 0.3125rem;
	padding: 2px;
}
#write>h5.md-focus:before {
	left: -1.875rem;
	top: 0.25rem;
	padding: 2px;
}
#write>h6.md-focus:before {
	left: -1.875rem;
	top: .125rem;
	padding: 2px;
}
/*@media screen and (min-width: 48em) {
	.h1,
	h1 {
		font-size: 3.250rem;
	}
	.h2,
	h2 {
		font-size: 2.298rem;
	}
	.h3,
	h3 {
		font-size: 1.625rem;
	}
	.h4,
	h4 {
		font-size: 1.250rem;
	}
	.h5,
	h5 {
		font-size: 1.150rem;
	}
	.h6,
	h6 {
		font-size: 1rem;
	}
	#write>h4.md-focus:before,
	#write>h5.md-focus:before,
	#write>h6.md-focus:before {
		top: 1px;
	}
	p {
		font-size: 1.25rem;
		line-height: 1.8;
	}
	table {
		font-size: 1.25rem;
	}
}*/
@media screen and (max-width: 48em) {
	blockquote {
		margin-left: 1rem;
		margin-right: 0;
		padding: 0.5em;
	}
	.h1,
	h1 {
		font-size: 2.827rem;
	}
	.h2,
	h2 {
		font-size: 1.999rem;
	}
	.h3,
	h3 {
		font-size: 1.413rem;
	}
	.h4,
	h4 {
		font-size: 1.250rem;
	}
	.h5,
	h5 {
		font-size: 1.150rem;
	}
	.h6,
	h6 {
		font-size: 1rem;
	}
}
a,
.md-def-url {
	color: #007ee5;
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
table {
	border: 1px solid #e2e2e2;
	margin-bottom: 20px
}
table th,
table td {
	padding: 8px;
	line-height: 1.5rem;
	vertical-align: top;
	border: 1px solid #e2e2e2;
}
table th {
	font-weight: normal;
	background-color: #f0f7fd;
}
table thead th {
	vertical-align: bottom
}
table caption+thead tr:first-child th,
table caption+thead tr:first-child td,
table colgroup+thead tr:first-child th,
table colgroup+thead tr:first-child td,
table thead:first-child tr:first-child th,
table thead:first-child tr:first-child td {
	border-top: 0
}
table tbody+tbody {
	border-top: 2px solid #ddd
}
code, .md-fences {
	padding: .5em;
	background: #f6f9fc;
	border: 1px solid #d0d4d9;
	border-radius: 3px;
	padding: .1em;
	font-size: 0.9rem !important;
	margin-left: 0.2em;
	margin-right: 0.2em;
}
.md-fences {
	margin: 0 0 20px;
	font-size: 1em;
	padding: 0.3em 1em;
  	padding-top: 0.4em;
}
.task-list{
	padding-left: 0;
}

.task-list-item {
	padding-left:2.125rem;
}

/* Chrome 29+ */
@media screen and (-webkit-min-device-pixel-ratio:0)
  and (min-resolution:.001dpcm) {
    .task-list-item input:before {
    	margin-top: -0.2rem;
    }

    .task-list-item input:checked:before,
	.task-list-item input[checked]:before {
		margin-top: -0.2rem;
	}
}

blockquote {
	margin: 0 0 1.11111rem;
	padding: 0.5rem 1.11111rem 0 1.05556rem;
	border-left: 2px solid rgba(0, 112, 224, 0.32);
}
blockquote,
blockquote p {
	line-height: 1.6;
	color: #8f8f8f;
}
#write pre.md-meta-block {
	min-height: 30px;
	background: #f8f8f8;
	padding: 1.5em;
	font-weight: 300;
	font-size: 1em;
	padding-bottom: 1.5em;
	padding-top: 3em;
    margin-top: -1.5em;
	color: #999;
	border-left: 1000px #f8f8f8 solid;
	margin-left: -1000px;
	border-right: 1000px #f8f8f8 solid;
	margin-right: -1000px;
	margin-bottom: 2em;
}
.MathJax_Display {
	font-size: 0.9em;
	margin-top: 0.5em;
	margin-bottom: 0;
}
p.mathjax-block,
.mathjax-block {
	padding-bottom: 0;
}
.mathjax-block>.code-tooltip {
	bottom: 5px;
	box-shadow: none;
}
.md-image>.md-meta {
	padding-left: 0.5em;
	padding-right: 0.5em;
}
.md-image>img {
	margin-top: 2px;
}
.md-image>.md-meta:first-of-type:before {
	padding-left: 4px;
}

#typora-source {
	color: #555;
}

/** ui for windows **/
#md-searchpanel {
    border-bottom: 1px solid #ccc;
}

#md-searchpanel .btn {
    border: 1px solid #ccc;
}

#md-notification:before {
	top: 14px;
}

#md-notification {
	background: #eee;
}

.megamenu-menu-panel .btn {
	border: 1px solid #ccc;
}

.mac-seamless-mode #typora-sidebar {
  background-color: #f7f9fa;
}

.pin-outline .outline-active {
  color: #0070E0; 
}

.file-list-item {
  border-bottom: 1px solid;
  border-color: #E6E8EB;
}

.file-list-item-summary {
  font-weight: 400;
  color: #637282; 
}

.file-list-item.active {
  color: #0070E0;
  background-color: #E6E8EB;
}

.file-tree-node.active>.file-node-background {
  background-color: #E6E8EB;
} 

.file-tree-node.active>.file-node-content {
  color: #0070E0;
}

.file-node-content {
  color: #5e676d;
}

.sidebar-tab.active {
  font-weight: 400;
}

code, kbd, pre, samp {
  font-family: "Roboto Mono", Menlo, monospace;
}



</style>
</head>
<body class='typora-export'>
<div id='write'  class=''><h1><a name="retro-propagação-backpropagation" class="md-header-anchor"></a><span>Retro-propagação (</span><em><span>Backpropagation</span></em><span>)</span></h1><p><span>Ref.: </span><a href='https://deepai.org/machine-learning-glossary-and-terms/backpropagation'><span>Backpropagation: DeepAI</span></a><span> (acessado em 04/03/2025) </span><span>&lt;</span><span>-- </span><em><span>Esta referência possui conteúdo incompleto, rever Dissertação de Mestrado,  para recordar equações e nomenclatura adotada &quot;antigamente&quot;</span></em><span>.</span></p><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n155"><a class="md-toc-inner" href="#retro-propagação-backpropagation">Retro-propagação (<em>Backpropagation</em>)</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n3"><a class="md-toc-inner" href="#-o-que-é-backpropagation">O que é <em>Backpropagation</em>?</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n8"><a class="md-toc-inner" href="#equações-de-retropropagação">Equações de Retropropagação</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n9"><a class="md-toc-inner" href="#definição-de-rede-neural-feedforward">Definição de Rede Neural Feedforward</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n17"><a class="md-toc-inner" href="#símbolos-de-fórmula-de-rede-neural-feedforward-explicados">Símbolos De Fórmula De Rede Neural Feedforward Explicados</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n41"><a class="md-toc-inner" href="#função-de-perda-para-retropropagação">Função de perda para retropropagação</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n57"><a class="md-toc-inner" href="#calculando-gradientes-com-a-regra-da-cadeia">Calculando gradientes com a regra da cadeia.</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n61"><a class="md-toc-inner" href="#calculando-gradientes-de-forma-mais-eficiente-com-o-algoritmo-de-retropropagação">Calculando gradientes de forma mais eficiente com o algoritmo de retropropagação</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n65"><a class="md-toc-inner" href="#calculando-a-retropropagação">Calculando a Retropropagação</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n86"><a class="md-toc-inner" href="#derivadas-compostas-na-rede">Derivadas (compostas) na rede</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n111"><a class="md-toc-inner" href="#retropropagação-padrão-vs-retropropagação-através-do-tempo">Retropropagação Padrão vs. Retropropagação Através do Tempo</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n120"><a class="md-toc-inner" href="#aplicações-de-backpropagação">Aplicações de Backpropagação</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n122"><a class="md-toc-inner" href="#retropropagação-em-redes-neurais-convolucionais-para-reconhecimento-facial">Retropropagação em redes neurais convolucionais para reconhecimento facial</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n127"><a class="md-toc-inner" href="#backpropagação-para-reconhecimento-de-fala">Backpropagação para reconhecimento de fala</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n130"><a class="md-toc-inner" href="#histórico-de-retropropagação">Histórico de Retropropagação</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n138"><a class="md-toc-inner" href="#referências">Referências</a></span></p></div><hr /><h2><a name="-o-que-é-backpropagation" class="md-header-anchor"></a><span>O que é </span><em><span>Backpropagation</span></em><span>?</span></h2><p><em><span>Backpropagation</span></em><span>, abreviação de propagação para trás de erros, é um método amplamente utilizado para calcular derivadas dentro de redes neurais profundas feedforward. A retropropagação forma uma parte importante de uma série de algoritmos de aprendizagem supervisionados para treinar redes neurais feedforward, como o </span><a href='https://deepai.org/machine-learning-glossary-and-terms/stochastic-gradient-descent'><span>gradiente descendente estocástico</span></a><span>.</span></p><p><span>Ao treinar uma rede neural por gradiente descendente, uma função de perda é calculada, que representa o quão longe as previsões da rede estão dos rótulos verdadeiros (</span><em><span>true labels</span></em><span>). A retro-propagação nos permite calcular o gradiente da função de perda em relação a cada um dos pesos da rede. Isso permite que cada peso seja atualizado individualmente para reduzir gradualmente a função de perda em muitas iterações de treinamento.</span></p><p><span>A retropropagação envolve o cálculo do gradiente que procede para trás através da rede feedforward desde a última camada até a primeira. Para calcular o gradiente em uma camada específica, os gradientes de todas as camadas a seguir são combinados através da </span><mark><span>regra da cadeia</span></mark><span> (da área de cálculo).</span></p><p><span>O algoritmo de retropropagação é fundamental para o aprendizado supervisionado de redes neurais profundas e permitiu o recente aumento na popularidade dos algoritmos de aprendizado profundo desde o início dos anos 2000.</span></p><h3><a name="equações-de-retropropagação" class="md-header-anchor"></a><span>Equações de Retropropagação</span></h3><h4><a name="definição-de-rede-neural-feedforward" class="md-header-anchor"></a><span>Definição de Rede Neural Feedforward</span></h4><p><span>Vamos considerar uma rede neural feedforward multicamadas com </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.062ex" height="1.877ex" viewBox="0 -755.9 888 808.1" role="img" focusable="false" style="vertical-align: -0.121ex;"><defs><path stroke-width="0" id="E28-MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E28-MJMATHI-4E" x="0" y="0"></use></g></svg></span><script type="math/tex">N</script><span> camadas.</span></p><p><span>A saída da primeira camada oculta é dada por</span></p><p><span>&lt;&lt;Fórmula de primeira camada da rede neural Feedforward&gt;&gt;</span></p><p><span>e a saída da segunda camada é dada por</span></p><p><span>&lt;&lt;Fórmula de segunda camada de rede neural Feedforward&gt;&gt;</span></p><p><span>E assim por diante, cada camada recebe a saída da camada anterior como entrada. A saída da camada final é denotada:</span></p><p><span>&lt;&lt;Fórmula de última camada da rede neural Feedforward&gt;&gt;</span></p><h3><a name="símbolos-de-fórmula-de-rede-neural-feedforward-explicados" class="md-header-anchor"></a><span>Símbolos De Fórmula De Rede Neural Feedforward Explicados</span></h3><p><span>Notação: </span><span>&lt;</span><span>-- Falta definir uma &quot;convensão&quot;</span></p><figure><table><thead><tr><th style='text-align:left;' ><span>Termo</span></th><th style='text-align:left;' ><span>Comentário</span></th></tr></thead><tbody><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.871ex" height="2.928ex" viewBox="0 -956.9 1236.3 1260.5" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E2-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E2-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="0" id="E2-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E2-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E2-MJMATHI-79" x="0" y="0"></use><g transform="translate(499,362)"><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-5B" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMATHI-69" x="278" y="0"></use><use transform="scale(0.707)" xlink:href="#E2-MJMAIN-5D" x="623" y="0"></use></g></g></svg></span><script type="math/tex">y^{[i]}</script></td><td style='text-align:left;' ><span>A saída da camada oculta </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.801ex" height="1.994ex" viewBox="0 -755.9 345 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E19-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMATHI-69" x="0" y="0"></use></g></svg></span><script type="math/tex">i</script></td></tr><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.413ex" height="2.577ex" viewBox="0 -806.1 1900 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E4-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E4-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E4-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E4-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E4-MJMATHI-66" x="0" y="0"></use><use xlink:href="#E4-MJMAIN-28" x="550" y="0"></use><use xlink:href="#E4-MJMATHI-78" x="939" y="0"></use><use xlink:href="#E4-MJMAIN-29" x="1511" y="0"></use></g></svg></span><script type="math/tex">f(x)</script></td><td style='text-align:left;' ><span>A </span><a href='https://deepai.org/machine-learning-glossary-and-terms/activation-function'><span>função de ativação</span></a><span> da camada oculta </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.801ex" height="1.994ex" viewBox="0 -755.9 345 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E19-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMATHI-69" x="0" y="0"></use></g></svg></span><script type="math/tex">i</script><span>, que pode ser uma função sigmóide, uma unidade linear retificada (ReLU), uma função tanh ou similar.</span></td></tr><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.375ex" height="2.461ex" viewBox="0 -956.9 1453.1 1059.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E6-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="0" id="E6-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="0" id="E6-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E6-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E6-MJMATHI-77" x="0" y="0"></use><g transform="translate(716,362)"><use transform="scale(0.707)" xlink:href="#E6-MJMAIN-5B" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E6-MJMATHI-69" x="278" y="0"></use><use transform="scale(0.707)" xlink:href="#E6-MJMAIN-5D" x="623" y="0"></use></g></g></svg></span><script type="math/tex">w^{[i]}</script></td><td style='text-align:left;' ><span>A matriz de pesos ocultos na camada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.801ex" height="1.994ex" viewBox="0 -755.9 345 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E19-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMATHI-69" x="0" y="0"></use></g></svg></span><script type="math/tex">i</script><span>.</span></td></tr><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.329ex" height="1.41ex" viewBox="0 -504.6 572 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E31-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E31-MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex">x</script></td><td style='text-align:left;' ><span>O vetor de entrada para a rede neural.</span></td></tr><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.394ex" height="1.41ex" viewBox="0 -504.6 600 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E9-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E9-MJMATHI-6E" x="0" y="0"></use></g></svg></span><script type="math/tex">n</script></td><td style='text-align:left;' ><span>O número de camadas na rede neural.</span></td></tr><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.708ex" height="2.461ex" viewBox="0 -956.9 1166.1 1059.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E10-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path stroke-width="0" id="E10-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="0" id="E10-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E10-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E10-MJMATHI-62" x="0" y="0"></use><g transform="translate(429,362)"><use transform="scale(0.707)" xlink:href="#E10-MJMAIN-5B" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E10-MJMATHI-69" x="278" y="0"></use><use transform="scale(0.707)" xlink:href="#E10-MJMAIN-5D" x="623" y="0"></use></g></g></svg></span><script type="math/tex">b^{[i]}</script></td><td style='text-align:left;' ><span>A matriz de viés (</span><em><span>bias</span></em><span>) na camada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.801ex" height="1.994ex" viewBox="0 -755.9 345 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E19-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMATHI-69" x="0" y="0"></use></g></svg></span><script type="math/tex">i</script><span>.</span></td></tr></tbody></table></figure><h3><a name="função-de-perda-para-retropropagação" class="md-header-anchor"></a><span>Função de perda para retropropagação</span></h3><p><span>Quando a rede feedforward aceita uma entrada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.329ex" height="1.41ex" viewBox="0 -504.6 572 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E31-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E31-MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex">x</script><span> e a passa pelas camadas para produzir uma saída, as informações fluem para frente através da rede. Isso é chamado de propagação para frente (</span><em><span>forward propagation</span></em><span>).</span></p><p><span>Durante o aprendizado supervisionado, a saída é comparada ao vetor do rótulo (</span><em><span>labels</span></em><span>) para dar uma função de perda, também chamada de função de custo, que representa o quão boa a rede é em fazer previsões:</span></p><p><span>&lt;&lt;Função de perda usada para backpropagation&gt;&gt;</span></p><p><span>A função de perda retorna um valor baixo quando a saída da rede está próxima do rótulo e um valor alto quando são diferentes. Portanto, no início do treinamento, a função de perda será muito grande, e um modelo totalmente treinado deve ter uma pequena função de perda, quando o conjunto de dados de treinamento for passado pela rede. Exemplos de funções de perda incluem a perda de entropia cruzada, a </span><a href='https://deepai.org/machine-learning-glossary-and-terms/cosine-similarity'><span>função de similaridade do cosseno</span></a><span> e a perda de dobradiça (</span><em><span>hinge loss</span></em><span>).</span></p><p><span>Durante o treinamento, o objetivo é reduzir a função de perda no conjunto de dados de treinamento o máximo possível. Isso significa que os pesos da rede devem ser ajustados gradualmente para que </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> seja reduzido.</span></p><p><span>Isso significa que devemos calcular a derivada de </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> em relação a cada peso na rede:</span></p><p><span>&lt;&lt;Derivado da função de custo necessária para a retropropagação&gt;&gt;</span></p><p><span>Símbolos da fórmula da função de perda de retropropagação explicados:</span></p><figure><table><thead><tr><th style='text-align:left;' ><span>Termo</span></th><th style='text-align:left;' ><span>Comentário</span></th></tr></thead><tbody><tr><td style='text-align:left;' ><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.318ex" height="3.861ex" viewBox="0 -1107.7 2720 1662.6" role="img" focusable="false" style="vertical-align: -1.289ex;"><defs><path stroke-width="0" id="E15-MJMATHI-57" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path><path stroke-width="0" id="E15-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="0" id="E15-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E15-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E15-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E15-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path stroke-width="0" id="E15-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path stroke-width="0" id="E15-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E15-MJMATHI-57" x="0" y="0"></use><g transform="translate(1079,521)"><use transform="scale(0.707)" xlink:href="#E15-MJMAIN-5B" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E15-MJMATHI-69" x="278" y="0"></use><use transform="scale(0.707)" xlink:href="#E15-MJMAIN-2212" x="623" y="0"></use><use transform="scale(0.707)" xlink:href="#E15-MJMAIN-31" x="1401" y="0"></use><use transform="scale(0.707)" xlink:href="#E15-MJMAIN-5D" x="1901" y="0"></use></g><g transform="translate(944,-327)"><use transform="scale(0.707)" xlink:href="#E15-MJMATHI-6A" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E15-MJMATHI-6B" x="412" y="0"></use></g></g></svg></span><script type="math/tex">W_{jk}^{[i-1]}</script></td><td style='text-align:left;' ><span>O peso da rede indo do nó </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.985ex" height="2.461ex" viewBox="-12 -755.9 424 1059.4" role="img" focusable="false" style="vertical-align: -0.705ex; margin-left: -0.028ex;"><defs><path stroke-width="0" id="E16-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E16-MJMATHI-6A" x="0" y="0"></use></g></svg></span><script type="math/tex">j</script><span> na camada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.609ex" height="2.577ex" viewBox="0 -806.1 2845.4 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E17-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E17-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E17-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E17-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E17-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E17-MJMAIN-28" x="0" y="0"></use><use xlink:href="#E17-MJMATHI-69" x="389" y="0"></use><use xlink:href="#E17-MJMAIN-2212" x="956" y="0"></use><use xlink:href="#E17-MJMAIN-31" x="1956" y="0"></use><use xlink:href="#E17-MJMAIN-29" x="2456" y="0"></use></g></svg></span><script type="math/tex">(i - 1)</script><span> para o nó </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.21ex" height="1.994ex" viewBox="0 -755.9 521 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E18-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E18-MJMATHI-6B" x="0" y="0"></use></g></svg></span><script type="math/tex">k</script><span> na camada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.801ex" height="1.994ex" viewBox="0 -755.9 345 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E19-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMATHI-69" x="0" y="0"></use></g></svg></span><script type="math/tex">i</script><span>.</span></td></tr></tbody></table></figure><h3><a name="calculando-gradientes-com-a-regra-da-cadeia" class="md-header-anchor"></a><span>Calculando gradientes com a regra da cadeia.</span></h3><p><span>Como uma rede neural tem muitas camadas, a derivada de </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> em um ponto no meio da rede pode estar muito distante da função de perda, que é calculada após a última camada.</span></p><p><span>Na verdade, </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> depende dos valores de peso através de uma cadeia de muitas funções. Podemos usar a regra da cadeia do cálculo para calcular seus derivados. A regra da cadeia nos diz que para uma função </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.087ex" height="1.41ex" viewBox="0 -504.6 468 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E25-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E25-MJMATHI-7A" x="0" y="0"></use></g></svg></span><script type="math/tex">z</script><span> dependendo de </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.154ex" height="1.877ex" viewBox="0 -504.6 497 808.1" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E34-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E34-MJMATHI-79" x="0" y="0"></use></g></svg></span><script type="math/tex">y</script><span>, onde depende de </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.329ex" height="1.41ex" viewBox="0 -504.6 572 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E31-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E31-MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex">x</script><span>, o derivado de </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.087ex" height="1.41ex" viewBox="0 -504.6 468 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E25-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E25-MJMATHI-7A" x="0" y="0"></use></g></svg></span><script type="math/tex">z</script><span> em relação a </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.329ex" height="1.41ex" viewBox="0 -504.6 572 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E31-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E31-MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex">x</script><span> é dado por:</span></p><p><span>&lt;&lt;A regra da cadeia do cálculo&gt;&gt;</span></p><h3><a name="calculando-gradientes-de-forma-mais-eficiente-com-o-algoritmo-de-retropropagação" class="md-header-anchor"></a><span>Calculando gradientes de forma mais eficiente com o algoritmo de retropropagação</span></h3><p><span>Cada componente da derivada de </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> em relação a cada peso na rede pode ser calculado individualmente usando a regra da cadeia. No entanto, seria extremamente ineficiente fazer isso separadamente para cada peso.</span></p><p><span>O algoritmo de backpropagação envolve primeiro o cálculo dos derivados na camada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.062ex" height="1.877ex" viewBox="0 -755.9 888 808.1" role="img" focusable="false" style="vertical-align: -0.121ex;"><defs><path stroke-width="0" id="E28-MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E28-MJMATHI-4E" x="0" y="0"></use></g></svg></span><script type="math/tex">N</script><span>, que é a última camada. Esses derivados são um ingrediente na fórmula de regra da cadeia para a camada </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.063ex" height="2.11ex" viewBox="0 -755.9 2610.4 908.7" role="img" focusable="false" style="vertical-align: -0.355ex;"><defs><path stroke-width="0" id="E29-MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path stroke-width="0" id="E29-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E29-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E29-MJMATHI-4E" x="0" y="0"></use><use xlink:href="#E29-MJMAIN-2212" x="1110" y="0"></use><use xlink:href="#E29-MJMAIN-31" x="2110" y="0"></use></g></svg></span><script type="math/tex">N - 1</script><span>, para que possam ser salvos e reutilizados para a penúltima camada. E assim, na retropropagação, trabalhamos de trás para frente através da rede, indo da última camada para a primeira camada, a cada vez usando os últimos cálculos derivados através da regra da cadeia para obter as derivadas para a camada atual.</span></p><p><span>Dessa forma, o algoritmo de retropropagação nos permite calcular eficientemente o gradiente em relação a cada peso, evitando cálculos duplicados.</span></p><h3><a name="calculando-a-retropropagação" class="md-header-anchor"></a><span>Calculando a Retropropagação</span></h3><p><span>Exemplo de Cálculo de Backpropagation: Rede Feedforward com duas camadas ocultas e função de perda sigmoidal.</span></p><p><em><span>Definindo uma rede neural feedforward como um gráfico computacional</span></em></p><p><span>Vamos considerar que estamos treinando uma rede neural de feedforward simples com duas camadas ocultas. Podemos representar a rede durante o treinamento como o seguinte gráfico computacional:</span></p><p><span>&lt;</span><falta figura><span>&gt;</span></p><p><span>Portanto, cada exemplo de treinamento entra na rede como um par </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.323ex" height="2.577ex" viewBox="0 -806.1 2291.7 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E30-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E30-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E30-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E30-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E30-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E30-MJMAIN-28" x="0" y="0"></use><use xlink:href="#E30-MJMATHI-78" x="389" y="0"></use><use xlink:href="#E30-MJMAIN-2C" x="961" y="0"></use><use xlink:href="#E30-MJMATHI-79" x="1405" y="0"></use><use xlink:href="#E30-MJMAIN-29" x="1902" y="0"></use></g></svg></span><script type="math/tex">(x, y)</script><span>, onde </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.329ex" height="1.41ex" viewBox="0 -504.6 572 607.1" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E31-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E31-MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex">x</script><span> é a observação e </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.154ex" height="1.877ex" viewBox="0 -504.6 497 808.1" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E34-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E34-MJMATHI-79" x="0" y="0"></use></g></svg></span><script type="math/tex">y</script><span> é o rótulo (</span><em><span>label</span></em><span>). A função de perda </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> é calculada a partir da saída e o rótulo (</span><em><span>label</span></em><span>) </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.154ex" height="1.877ex" viewBox="0 -504.6 497 808.1" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E34-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E34-MJMATHI-79" x="0" y="0"></use></g></svg></span><script type="math/tex">y</script><span>. </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.765ex" height="2.11ex" viewBox="0 -806.1 760 908.7" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E35-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E35-MJMATHI-43" x="0" y="0"></use></g></svg></span><script type="math/tex">C</script><span> deve ser minimizado durante o treinamento.</span></p><p><em><span>Expressando a rede neural feedforward como uma combinação de funções</span></em></p><p><span>Vamos simplificar e definir os valores de viés (</span><em><span>bias</span></em><span>) para zero, e tratar os vetores como escalares, para tornar o cálculo mais conciso. Isso significa que nossa rede tem dois parâmetros para treinar,</span></p><p><span>?? </span></p><p><span>E</span></p><p><span>??.</span></p><p><span>Então a saída da primeira camada oculta é:</span></p><p><span>&lt;&lt;falta equação&gt;&gt;</span></p><p><span>A saída da segunda camada oculta é:</span></p><p><span>&lt;&lt;falta equação&gt;&gt;</span></p><p><span>A saída da camada final é:</span></p><p><span>&lt;&lt;falta equação&gt;&gt;</span></p><p><span>E, finalmente, vamos escolher a </span><mark><span>função de erro médio quadrático</span></mark><span> simples como nossa função de perda (</span><mark><em><span>loss function</span></em></mark><span>):</span></p><p><span>&lt;&lt;falta equação&gt;&gt;</span></p><p><span>e vamos definir as funções de ativação em ambas as camadas ocultas para a função sigmoid:</span></p><p><span>&lt;&lt;falta equação&gt;&gt;</span></p><h3><a name="derivadas-compostas-na-rede" class="md-header-anchor"></a><span>Derivadas (compostas) na rede</span></h3><p><span>Será útil conhecer com antecedência as derivadas da função de perda e da função de ativação (sigmoide):</span></p><p><span>&lt;&lt;falta equação&gt;&gt;</span></p><p><span>Usando a retropropagação, primeiro calculamos:</span></p><p><span>&lt;&lt;equação&gt;&gt;</span></p><p><span>, então</span></p><p><span>&lt;&lt;nova equação&gt;&gt;</span></p><p><span>, e então</span></p><p><span>&lt;&lt;outra equação&gt;&gt;</span></p><p><span>, trabalhando para trás através da rede.</span></p><p><span>Podemos expressar a função de perda explicitamente como uma função de todos os pesos na rede substituindo a expressão para cada camada:</span></p><p><strong><span>Retropropagação etapa 1</span></strong><span>: Calculando o gradiente na terceira e última camada</span></p><p><span>Primeiro, queremos calcular o gradiente do último peso na rede (camada 3). Aplicando a regra da cadeia e trabalhando ao contrário no gráfico computacional, o betemos:</span></p><p><span>&lt;&lt;falta equações !?&gt;&gt;</span></p><p><strong><span>Retropropagação etapa 2</span></strong><span>: Calculando o gradiente na segunda (penúltima) camada</span></p><p><span>Em seguida, calcularemos o gradiente na camada 2. Como C está agora a dois passos da camada 2, temos que usar a regra da cadeia duas vezes:</span></p><p><span>&lt;&lt;faltam equações&gt;&gt;</span></p><p><span>Observe que o primeiro termo na expressão de regra da cadeia é o mesmo que o primeiro termo na expressão para a camada 3.</span></p><p><strong><span>Passo de retropropagação 3</span></strong><span>: Calculando o gradiente na primeira camada</span></p><p><span>Finalmente, podemos calcular o gradiente em relação ao peso na camada 1, desta vez usando outra etapa da regra da cadeia.</span></p><p><span>&lt;&lt;falta equações !?&gt;&gt;</span></p><p><span>Os dois primeiros termos na expressão de regra de cadeia para a camada 1 são compartilhados com o cálculo do gradiente para a camada 2.</span></p><p><span>Isso significa que computacionalmente, não é necessário recalcular toda a expressão. Somente os termos que são específicos da camada atual devem ser avaliados. Os termos que são comuns às camadas anteriores podem ser reciclados.</span></p><p><span>Dessa forma, o algoritmo de backpropagation é extremamente eficiente, em comparação com uma abordagem ingênua, que envolveria a avaliação da regra da cadeia para cada peso na rede individualmente.</span></p><p><span>Uma vez que os gradientes sejam calculados, seria normal atualizar todos os pesos na rede com o objetivo de reduzir C. Há vários algoritmos para conseguir isso, e o mais conhecido é a descida de gradiente estocástico.</span></p><h3><a name="retropropagação-padrão-vs-retropropagação-através-do-tempo" class="md-header-anchor"></a><span>Retropropagação Padrão vs. Retropropagação Através do Tempo</span></h3><p><span>A retropropagação depende da capacidade de expressar uma rede neural inteira em função de uma função de uma função de uma função... e assim por diante, permitindo que a regra da cadeia seja aplicada recursivamente.</span></p><p><span>Isso não pode ser aplicado se a rede neural não puder ser reduzida a uma única expressão de funções compostas - em outras palavras, se não puder ser expressa como um gráfo acíclico direcionado.</span></p><p><span>Uma </span><a href='https://deepai.org/machine-learning-glossary-and-terms/recurrent-neural-network'><span>rede neural recorrente</span></a><span> processa uma série temporal de entrada, e a saída de um nó em um ponto no tempo é alimentada de volta para a rede no ponto de tempo seguinte. Isso significa que uma rede neural recorrente não pode ser expressa como um gráfico acíclico direcionado, uma vez que contém ciclos.</span></p><p><span>No entanto, é possível &#39;desenrolar&#39; (</span><em><span>unroll</span></em><span>) uma rede neural recorrente e visualizá-la como uma rede neural feedforward. Cada passo de tempo é representado como uma única cópia da rede neural original.</span></p><p><span>&lt;&lt;falta equação !?&gt;&gt;</span></p><p><em><span>Desenrolando uma rede neural recorrente para representá-la como uma rede neural feedforward para retropropagação através do tempo</span></em></p><p><span>Como a retropropagação ao longo do tempo envolve a duplicação da rede, ela pode produzir uma grande rede neural de feedforward que é difícil de treinar, com muitas oportunidades para o algoritmo de backpropagação ficar preso em optima local.</span></p><p><span>Além disso, as interações entre entradas que estão distantes no tempo podem ser difíceis para a rede aprender, pois as contribuições do gradiente da interação se tornam cada vez menores em comparação com os efeitos locais. Isso é conhecido como o </span><mark><span>problema do desaparecimento do gradiente (</span><a href='https://deepai.org/machine-learning-glossary-and-terms/vanishing-gradient-problem'><strong><em><span>vanishing gradient problem</span></em></strong></a><span>)</span></mark><span> e pode ser resolvido escolhendo </span><mark><span>funções de ativação ReLU</span></mark><span> e introduzindo a </span><mark><span>regularização na rede</span></mark><span>.</span></p><h3><a name="aplicações-de-backpropagação" class="md-header-anchor"></a><span>Aplicações de Backpropagação</span></h3><p><span>A backpropagação e suas variantes, como a backpropagação ao longo do tempo, são amplamente utilizadas para treinar quase todos os tipos de redes neurais e permitiram o recente aumento na popularidade do aprendizado profundo. Uma pequena seleção de exemplos de aplicações de retropropagação é apresentada abaixo.</span></p><h4><a name="retropropagação-em-redes-neurais-convolucionais-para-reconhecimento-facial" class="md-header-anchor"></a><span>Retropropagação em redes neurais convolucionais para reconhecimento facial</span></h4><p><span>As redes neurais convolucionais (</span><a href='https://deepai.org/machine-learning-glossary-and-terms/convolutional-neural-network'><em><span>Convolutional neural networks</span></em></a><span>) são a </span><mark><span>técnica padrão de aprendizado profundo para processamento e reconhecimento de imagens</span></mark><span>, e são frequentemente treinadas com o </span><mark><span>algoritmo de retropropagação</span></mark><span>.</span></p><p><span>Em 2015, Parkhi, Vidaldi e Zisserman descreveram uma técnica para construir um reconhecimento facial. Eles usaram uma rede neural convolucional com 18 camadas e um banco de dados de rostos de celebridades.</span></p><p><span>Inicialmente, a rede foi treinada usando backpropagation em todas as 18 camadas. As imagens foram passadas para a rede em lotes, a função de perda foi calculada e os gradientes foram calculados primeiro para a camada 18, trabalhando de volta para a camada 1. Após cada lote (</span><em><span>batch</span></em><span>) de imagens, os pesos da rede foram atualizados.</span></p><p><span>Para refinar a rede para poder distinguir as nuances dos rostos humanos, os pesquisadores executaram um </span><mark><span>estágio de treinamento extra apenas para a camada 18</span></mark><span>, uma vez que a backpropagation tivesse sido executada para todas as 18 camadas. Os pesquisadores escolheram uma função de perda chamada perda de trigêmeos(!?) (</span><em><span>triplet loss</span></em><span>). A rede neural recebe uma entrada de três imagens de rosto de celebridades ao mesmo tempo, por exemplo, duas imagens de Matt Damon e uma imagem de Brad Pitt. A função de perda penaliza a rede se decidir que duas imagens da mesma pessoa são diferentes, e também penaliza a rede por classificar imagens de pessoas diferentes como semelhantes. Com o tempo, </span><em><span>triplets</span></em><span> de três imagens são passados pela rede e a função de perda é calculada, e os pesos da última camada são atualizados.</span></p><h4><a name="backpropagação-para-reconhecimento-de-fala" class="md-header-anchor"></a><span>Backpropagação para reconhecimento de fala</span></h4><p><span>O algoritmo de backpropagation foi aplicado para reconhecimento de fala. Um exemplo de implementação de um sistema de reconhecimento de voz para inglês e japonês, capaz de ser executado em dispositivos embarcados, foi desenvolvido pela Sony Corporation of Japan. O sistema foi projetado para ouvir um número limitado de comandos de um usuário.</span></p><p><span>Nesta implementação, um sinal de som de entrada é dividido em janelas de tempo e uma </span><strong><span>Transformada Rápida de Fourier</span></strong><span> (</span><em><span>Fast Fourier Transform</span></em><span>) é aplicada. A intensidade do som em diferentes frequências (</span><em><span>o espectro do sinal</span></em><span>) é tomada como uma característica (</span><em><span>feature</span></em><span>) e inserida em uma rede neural composta por cinco camadas. Os pesquisadores escolheram uma </span><mark><span>função de perda de entropia cruzada Softmax</span></mark><span> e conseguiram aplicar a retropropagação para treinar as cinco camadas para entender os comandos japoneses. Eles foram então capazes de mudar a rede para treinar em gravações de som em inglês e foram capazes de adaptar o sistema para reconhecer comandos em inglês. </span><mark><span>Este é um exemplo de </span><strong><span>transferência de aprendizado (</span><em><span>transfer learning</span></em><span>)</span></strong><span>: um modelo de aprendizado de máquina pode ser treinado para uma tarefa e, em seguida, retreinado e adaptado para uma nova tarefa.</span></mark></p><h3><a name="histórico-de-retropropagação" class="md-header-anchor"></a><span>Histórico de Retropropagação</span></h3><p><em><span>Augustin-Louis Cauchy (1789-1857), inventor da descendência gradiente. A imagem é de domínio público.</span></em></p><p><span>Em 1847, o matemático francês Baron Augustin-Louis Cauchy desenvolveu um método de descida de gradiente para resolver equações simultâneas. Ele estava interessado em resolver cálculos astronômicos em muitas variáveis, e teve a ideia de pegar a derivada de uma função e dar pequenos passos para minimizar um termo de erro.</span></p><p><span>No século seguinte, os métodos de descida de gradiente foram usados em todas as disciplinas para resolver problemas difíceis numericamente, onde uma solução algébrica exata teria sido impossível ou computacionalmente intratável.</span></p><p><span>Em 1970, o estudante de mestrado finlandês Seppo Linnainmaa descreveu um algoritmo eficiente para retropropagação de erros em redes escassamente (</span><em><span>sparsely</span></em><span>) conectadas em sua tese de mestrado na Universidade de Helsinque, embora ele não tenha se referido especificamente a redes neurais.</span></p><p><span>Em 1986, o </span><mark><span>psicólogo americano David Rumelhart</span></mark><span> e seus colegas publicaram um artigo influente aplicando o algoritmo de retropropagação de Linnainmaa a redes neurais multicamadas. Os anos seguintes viram vários avanços com base no novo algoritmo, como o artigo de </span><mark><span>Yann LeCun de 1989 aplicando retropropagação em redes neurais convolucionais para reconhecimento de dígitos escritos à mão</span></mark><span>.</span></p><p><span>Na década de 1980, vários pesquisadores derivaram independentemente a </span><mark><span>retropropagação considerando o tempo</span></mark><span>, a fim de permitir o treinamento de </span><mark><span>redes neurais recorrentes</span></mark><span>.</span></p><p><span>Nos últimos anos, as </span><mark><span>redes neurais profundas</span></mark><span> tornaram-se onipresentes (</span><em><span>ubiquitous</span></em><span>) e a retropropagação é muito importante para um treinamento eficiente. Embora o algoritmo tenha sido modificado para ser paralelizado e executado facilmente em várias GPUs, o algoritmo de backpropagação original de Linnainmaa e Rumelhart formam a espinha dorsal de toda a IA baseada em aprendizado profundo hoje.</span></p><h3><a name="referências" class="md-header-anchor"></a><span>Referências</span></h3><ul><li><span>Murphy, Machine Learning: A Probabilistic Perspective (</span><em><span>Aprendizado de Máquina: Uma Perspectiva Probabilística</span></em><span>) (2012)</span></li><li><span>Goodfellow et al, Deep Learning (</span><em><span>Aprendizagem Profunda</span></em><span>) (2016)</span></li><li><span>Cauchy, Méthode générale pour la résolution des systèmes d’équations simultanées (1847)</span></li><li><span>Lecun, Backpropagation Applied to Handwritten Zip Code Recognition (1989)</span></li><li><span>Parkhi et al, Deep Face Recognition (2015)</span></li><li><span>Tsunoo et al (Sony Corporation, Japan), End-to-end Adaptation with Backpropagation through WFST for On-device Speech Recognition System (2019)</span></li></ul><hr /><p>&nbsp;</p></div>
</body>
</html>